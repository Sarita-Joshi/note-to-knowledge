{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "945ca213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install llama-index graspologic numpy==1.24.4 scipy==1.12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a14d29b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "text= \"\"\"\n",
    "The History and Impact of Quantum Mechanics\n",
    "\n",
    "Quantum mechanics is a fundamental theory in physics that describes nature at the smallest scales, such as atoms and subatomic particles. It was developed in the early 20th century, revolutionizing our understanding of the physical world.\n",
    "\n",
    "The origins of quantum mechanics trace back to Max Planck’s work in 1900, where he introduced the idea of quantized energy levels to explain blackbody radiation. This concept was further developed by Albert Einstein in 1905 when he explained the photoelectric effect by proposing that light consists of discrete packets of energy called photons. Einstein’s work earned him the Nobel Prize in Physics in 1921.\n",
    "\n",
    "Building on these ideas, Niels Bohr proposed the Bohr model of the atom in 1913, which described electrons orbiting the nucleus in fixed energy levels. This model successfully explained the spectral lines of hydrogen but had limitations with more complex atoms.\n",
    "\n",
    "In the 1920s, Werner Heisenberg formulated matrix mechanics, and Erwin Schrödinger developed wave mechanics, two equivalent formulations of quantum mechanics. Schrödinger’s wave equation describes how the quantum state of a physical system changes over time.\n",
    "\n",
    "Werner Heisenberg is also famous for the uncertainty principle, which states that certain pairs of physical properties, like position and momentum, cannot be simultaneously known to arbitrary precision.\n",
    "\n",
    "Quantum mechanics has had profound implications beyond physics. It laid the foundation for quantum chemistry, explaining chemical bonding and reactions. It also enabled the development of semiconductors, which are the basis for modern electronics, including computers and smartphones.\n",
    "\n",
    "Richard Feynman, a prominent physicist of the 20th century, contributed significantly to quantum electrodynamics (QED), a quantum theory of the interaction between light and matter. Feynman introduced Feynman diagrams, a pictorial representation of particle interactions.\n",
    "\n",
    "The theory of quantum mechanics also paved the way for emerging fields such as quantum computing and quantum cryptography. Quantum computers use quantum bits, or qubits, which can represent both 0 and 1 simultaneously, promising exponential speedups for certain computational problems.\n",
    "\n",
    "Despite its successes, quantum mechanics challenges our classical intuitions about reality. Concepts like superposition and entanglement defy everyday experience but have been experimentally confirmed.\n",
    "\n",
    "The Copenhagen interpretation, primarily developed by Niels Bohr and Werner Heisenberg, is one of the earliest and most widely taught interpretations of quantum mechanics. It emphasizes the probabilistic nature of quantum measurements and the role of the observer.\n",
    "\n",
    "Today, research in quantum mechanics continues to expand, with scientists exploring quantum gravity, quantum field theory, and applications in materials science and information technology.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eea5d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [Document(text=text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "57fa2328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# 1. Load environment variables for API keys\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2e79bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install llama-index-llms-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "48fb2e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_200\\2082969730.py:3: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/)\n",
      "  llm = Gemini(api_key=GEMINI_API_KEY, model=\"gemini-1.5-flash\")  # or \"gemini-pro\", etc.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.gemini import Gemini\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "llm = Gemini(api_key=GEMINI_API_KEY, model=\"gemini-1.5-flash\")  # or \"gemini-pro\", etc.\n",
    "\n",
    "# from llama_index.llms.groq import Groq\n",
    "# llm = Groq(api_key=GROQ_API_KEY, model=\"llama3-70b-8192\")  # or \"llama-3-70b-8192\", etc.\n",
    "\n",
    "# ---- Use OPenai ----\n",
    "# llm = OpenAI(model=\"gpt-4-turbo\")  # You can use \"gpt-3.5-turbo\" for lower cost\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a35bb519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from typing import Any, List, Callable, Optional, Union, Dict\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from llama_index.core.async_utils import run_jobs\n",
    "from llama_index.core.indices.property_graph.utils import (\n",
    "    default_parse_triplets_fn,\n",
    ")\n",
    "from llama_index.core.graph_stores.types import (\n",
    "    EntityNode,\n",
    "    KG_NODES_KEY,\n",
    "    KG_RELATIONS_KEY,\n",
    "    Relation,\n",
    ")\n",
    "from llama_index.core.llms.llm import LLM\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.prompts.default_prompts import (\n",
    "    DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
    ")\n",
    "from llama_index.core.schema import TransformComponent, BaseNode\n",
    "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class GraphRAGExtractor(TransformComponent):\n",
    "    \"\"\"Extract triples from a graph.\n",
    "\n",
    "    Uses an LLM and a simple prompt + output parsing to extract paths (i.e. triples) and entity, relation descriptions from text.\n",
    "\n",
    "    Args:\n",
    "        llm (LLM):\n",
    "            The language model to use.\n",
    "        extract_prompt (Union[str, PromptTemplate]):\n",
    "            The prompt to use for extracting triples.\n",
    "        parse_fn (callable):\n",
    "            A function to parse the output of the language model.\n",
    "        num_workers (int):\n",
    "            The number of workers to use for parallel processing.\n",
    "        max_paths_per_chunk (int):\n",
    "            The maximum number of paths to extract per chunk.\n",
    "    \"\"\"\n",
    "\n",
    "    llm: LLM\n",
    "    extract_prompt: PromptTemplate\n",
    "    parse_fn: Callable\n",
    "    num_workers: int\n",
    "    max_paths_per_chunk: int\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: Optional[LLM] = None,\n",
    "        extract_prompt: Optional[Union[str, PromptTemplate]] = None,\n",
    "        parse_fn: Callable = default_parse_triplets_fn,\n",
    "        max_paths_per_chunk: int = 10,\n",
    "        num_workers: int = 4,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        from llama_index.core import Settings\n",
    "\n",
    "        if isinstance(extract_prompt, str):\n",
    "            extract_prompt = PromptTemplate(extract_prompt)\n",
    "\n",
    "        super().__init__(\n",
    "            llm=llm or Settings.llm,\n",
    "            extract_prompt=extract_prompt or DEFAULT_KG_TRIPLET_EXTRACT_PROMPT,\n",
    "            parse_fn=parse_fn,\n",
    "            num_workers=num_workers,\n",
    "            max_paths_per_chunk=max_paths_per_chunk,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def class_name(cls) -> str:\n",
    "        return \"GraphExtractor\"\n",
    "\n",
    "    def __call__(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[BaseNode]:\n",
    "        \"\"\"Extract triples from nodes.\"\"\"\n",
    "        return asyncio.run(\n",
    "            self.acall(nodes, show_progress=show_progress, **kwargs)\n",
    "        )\n",
    "\n",
    "    async def _aextract(self, node: BaseNode) -> BaseNode:\n",
    "        \"\"\"Extract triples from a node.\"\"\"\n",
    "        assert hasattr(node, \"text\")\n",
    "\n",
    "        text = node.get_content(metadata_mode=\"llm\")\n",
    "        try:\n",
    "            llm_response = await self.llm.apredict(\n",
    "                self.extract_prompt,\n",
    "                text=text,\n",
    "                max_knowledge_triplets=self.max_paths_per_chunk,\n",
    "            )\n",
    "            entities, entities_relationship = self.parse_fn(llm_response)\n",
    "        except ValueError:\n",
    "            entities = []\n",
    "            entities_relationship = []\n",
    "\n",
    "        existing_nodes = node.metadata.pop(KG_NODES_KEY, [])\n",
    "        existing_relations = node.metadata.pop(KG_RELATIONS_KEY, [])\n",
    "        entity_metadata = node.metadata.copy()\n",
    "        for entity, entity_type, description in entities:\n",
    "            entity_metadata[\"entity_description\"] = description\n",
    "            entity_node = EntityNode(\n",
    "                name=entity, label=entity_type, properties=entity_metadata\n",
    "            )\n",
    "            existing_nodes.append(entity_node)\n",
    "\n",
    "        relation_metadata = node.metadata.copy()\n",
    "        for triple in entities_relationship:\n",
    "            subj, obj, rel, description = triple\n",
    "            relation_metadata[\"relationship_description\"] = description\n",
    "            rel_node = Relation(\n",
    "                label=rel,\n",
    "                source_id=subj,\n",
    "                target_id=obj,\n",
    "                properties=relation_metadata,\n",
    "            )\n",
    "\n",
    "            existing_relations.append(rel_node)\n",
    "\n",
    "        node.metadata[KG_NODES_KEY] = existing_nodes\n",
    "        node.metadata[KG_RELATIONS_KEY] = existing_relations\n",
    "        return node\n",
    "\n",
    "    async def acall(\n",
    "        self, nodes: List[BaseNode], show_progress: bool = False, **kwargs: Any\n",
    "    ) -> List[BaseNode]:\n",
    "        \"\"\"Extract triples from nodes async.\"\"\"\n",
    "        jobs = []\n",
    "        for node in nodes:\n",
    "            jobs.append(self._aextract(node))\n",
    "\n",
    "        return await run_jobs(\n",
    "            jobs,\n",
    "            workers=self.num_workers,\n",
    "            show_progress=show_progress,\n",
    "            desc=\"Extracting paths from text\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d3a1f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "42be8c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from llama_index.core.graph_stores import SimplePropertyGraphStore\n",
    "import networkx as nx\n",
    "from graspologic.partition import hierarchical_leiden\n",
    "\n",
    "from llama_index.core.llms import ChatMessage\n",
    "\n",
    "\n",
    "class GraphRAGStore(SimplePropertyGraphStore):\n",
    "    community_summary = {}\n",
    "    max_cluster_size = 5\n",
    "\n",
    "    def generate_community_summary(self, text):\n",
    "        \"\"\"Generate summary for a given text using an LLM.\"\"\"\n",
    "        messages = [\n",
    "            ChatMessage(\n",
    "                role=\"system\",\n",
    "                content=(\n",
    "                    \"You are provided with a set of relationships from a knowledge graph, each represented as \"\n",
    "                    \"entity1->entity2->relation->relationship_description. Your task is to create a summary of these \"\n",
    "                    \"relationships. The summary should include the names of the entities involved and a concise synthesis \"\n",
    "                    \"of the relationship descriptions. The goal is to capture the most critical and relevant details that \"\n",
    "                    \"highlight the nature and significance of each relationship. Ensure that the summary is coherent and \"\n",
    "                    \"integrates the information in a way that emphasizes the key aspects of the relationships.\"\n",
    "                ),\n",
    "            ),\n",
    "            ChatMessage(role=\"user\", content=text),\n",
    "        ]\n",
    "        response = Gemini().chat(messages)\n",
    "        clean_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
    "        return clean_response\n",
    "\n",
    "    def build_communities(self):\n",
    "        \"\"\"Builds communities from the graph and summarizes them.\"\"\"\n",
    "        nx_graph = self._create_nx_graph()\n",
    "        community_hierarchical_clusters = hierarchical_leiden(\n",
    "            nx_graph, max_cluster_size=self.max_cluster_size\n",
    "        )\n",
    "        community_info = self._collect_community_info(\n",
    "            nx_graph, community_hierarchical_clusters\n",
    "        )\n",
    "        self._summarize_communities(community_info)\n",
    "\n",
    "    def _create_nx_graph(self):\n",
    "        \"\"\"Converts internal graph representation to NetworkX graph.\"\"\"\n",
    "        nx_graph = nx.Graph()\n",
    "        for node in self.graph.nodes.values():\n",
    "            nx_graph.add_node(str(node))\n",
    "        for relation in self.graph.relations.values():\n",
    "            nx_graph.add_edge(\n",
    "                relation.source_id,\n",
    "                relation.target_id,\n",
    "                relationship=relation.label,\n",
    "                description=relation.properties[\"relationship_description\"],\n",
    "            )\n",
    "        return nx_graph\n",
    "\n",
    "    def _collect_community_info(self, nx_graph, clusters):\n",
    "        \"\"\"Collect detailed information for each node based on their community.\"\"\"\n",
    "        community_mapping = {item.node: item.cluster for item in clusters}\n",
    "        community_info = {}\n",
    "        for item in clusters:\n",
    "            cluster_id = item.cluster\n",
    "            node = item.node\n",
    "            if cluster_id not in community_info:\n",
    "                community_info[cluster_id] = []\n",
    "\n",
    "            for neighbor in nx_graph.neighbors(node):\n",
    "                if community_mapping[neighbor] == cluster_id:\n",
    "                    edge_data = nx_graph.get_edge_data(node, neighbor)\n",
    "                    if edge_data:\n",
    "                        detail = f\"{node} -> {neighbor} -> {edge_data['relationship']} -> {edge_data['description']}\"\n",
    "                        community_info[cluster_id].append(detail)\n",
    "        return community_info\n",
    "\n",
    "    def _summarize_communities(self, community_info):\n",
    "        \"\"\"Generate and store summaries for each community.\"\"\"\n",
    "        for community_id, details in community_info.items():\n",
    "            details_text = (\n",
    "                \"\\n\".join(details) + \".\"\n",
    "            )  # Ensure it ends with a period\n",
    "            self.community_summary[\n",
    "                community_id\n",
    "            ] = self.generate_community_summary(details_text)\n",
    "\n",
    "    def get_community_summaries(self):\n",
    "        \"\"\"Returns the community summaries, building them if not already done.\"\"\"\n",
    "        if not self.community_summary:\n",
    "            self.build_communities()\n",
    "        return self.community_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b92aa9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install graspologic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bccf8c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_engine import CustomQueryEngine\n",
    "from llama_index.core.llms import LLM\n",
    "\n",
    "\n",
    "class GraphRAGQueryEngine(CustomQueryEngine):\n",
    "    graph_store: GraphRAGStore\n",
    "    llm: LLM\n",
    "\n",
    "    def custom_query(self, query_str: str) -> str:\n",
    "        \"\"\"Process all community summaries to generate answers to a specific query.\"\"\"\n",
    "        community_summaries = self.graph_store.get_community_summaries()\n",
    "        community_answers = [\n",
    "            self.generate_answer_from_summary(community_summary, query_str)\n",
    "            for _, community_summary in community_summaries.items()\n",
    "        ]\n",
    "\n",
    "        final_answer = self.aggregate_answers(community_answers)\n",
    "        return final_answer\n",
    "\n",
    "    def generate_answer_from_summary(self, community_summary, query):\n",
    "        \"\"\"Generate an answer from a community summary based on a given query using LLM.\"\"\"\n",
    "        prompt = (\n",
    "            f\"Given the community summary: {community_summary}, \"\n",
    "            f\"how would you answer the following query? Query: {query}\"\n",
    "        )\n",
    "        messages = [\n",
    "            ChatMessage(role=\"system\", content=prompt),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=\"I need an answer based on the above information.\",\n",
    "            ),\n",
    "        ]\n",
    "        response = self.llm.chat(messages)\n",
    "        cleaned_response = re.sub(r\"^assistant:\\s*\", \"\", str(response)).strip()\n",
    "        return cleaned_response\n",
    "\n",
    "    def aggregate_answers(self, community_answers):\n",
    "        \"\"\"Aggregate individual community answers into a final, coherent response.\"\"\"\n",
    "        # intermediate_text = \" \".join(community_answers)\n",
    "        prompt = \"Combine the following intermediate answers into a final, concise response.\"\n",
    "        messages = [\n",
    "            ChatMessage(role=\"system\", content=prompt),\n",
    "            ChatMessage(\n",
    "                role=\"user\",\n",
    "                content=f\"Intermediate answers: {community_answers}\",\n",
    "            ),\n",
    "        ]\n",
    "        final_response = self.llm.chat(messages)\n",
    "        cleaned_final_response = re.sub(\n",
    "            r\"^assistant:\\s*\", \"\", str(final_response)\n",
    "        ).strip()\n",
    "        return cleaned_final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "054d8051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=20,\n",
    ")\n",
    "nodes = splitter.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "84caed8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "289a870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "KG_TRIPLET_EXTRACT_TMPL = \"\"\"\n",
    "-Goal-\n",
    "Given a text document, identify all entities and their entity types from the text and all relationships among the identified entities.\n",
    "Given the text, extract up to {max_knowledge_triplets} entity-relation triplets.\n",
    "\n",
    "-Steps-\n",
    "1. Identify all entities. For each identified entity, extract the following information:\n",
    "- entity_name: Name of the entity, capitalized\n",
    "- entity_type: Type of the entity\n",
    "- entity_description: Comprehensive description of the entity's attributes and activities\n",
    "\n",
    "2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\n",
    "For each pair of related entities, extract the following information:\n",
    "- source_entity: name of the source entity, as identified in step 1\n",
    "- target_entity: name of the target entity, as identified in step 1\n",
    "- relation: relationship between source_entity and target_entity\n",
    "- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\n",
    "\n",
    "3. Output Formatting:\n",
    "- Return the result in valid JSON format with two keys: 'entities' (list of entity objects) and 'relationships' (list of relationship objects).\n",
    "- Exclude any text outside the JSON structure (e.g., no explanations or comments).\n",
    "- If no entities or relationships are identified, return empty lists: { \"entities\": [], \"relationships\": [] }.\n",
    "\n",
    "-An Output Example-\n",
    "{\n",
    "  \"entities\": [\n",
    "    {\n",
    "      \"entity_name\": \"Albert Einstein\",\n",
    "      \"entity_type\": \"Person\",\n",
    "      \"entity_description\": \"Albert Einstein was a theoretical physicist who developed the theory of relativity and made significant contributions to physics.\"\n",
    "    },\n",
    "    {\n",
    "      \"entity_name\": \"Theory of Relativity\",\n",
    "      \"entity_type\": \"Scientific Theory\",\n",
    "      \"entity_description\": \"A scientific theory developed by Albert Einstein, describing the laws of physics in relation to observers in different frames of reference.\"\n",
    "    },\n",
    "    {\n",
    "      \"entity_name\": \"Nobel Prize in Physics\",\n",
    "      \"entity_type\": \"Award\",\n",
    "      \"entity_description\": \"A prestigious international award in the field of physics, awarded annually by the Royal Swedish Academy of Sciences.\"\n",
    "    }\n",
    "  ],\n",
    "  \"relationships\": [\n",
    "    {\n",
    "      \"source_entity\": \"Albert Einstein\",\n",
    "      \"target_entity\": \"Theory of Relativity\",\n",
    "      \"relation\": \"developed\",\n",
    "      \"relationship_description\": \"Albert Einstein is the developer of the theory of relativity.\"\n",
    "    },\n",
    "    {\n",
    "      \"source_entity\": \"Albert Einstein\",\n",
    "      \"target_entity\": \"Nobel Prize in Physics\",\n",
    "      \"relation\": \"won\",\n",
    "      \"relationship_description\": \"Albert Einstein won the Nobel Prize in Physics in 1921.\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "-Real Data-\n",
    "######################\n",
    "text: {text}\n",
    "######################\n",
    "output:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5d63ad9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def parse_fn(response_str: str) -> Any:\n",
    "    json_pattern = r\"\\{.*\\}\"\n",
    "    match = re.search(json_pattern, response_str, re.DOTALL)\n",
    "    entities = []\n",
    "    relationships = []\n",
    "    if not match:\n",
    "        return entities, relationships\n",
    "    json_str = match.group(0)\n",
    "    try:\n",
    "        data = json.loads(json_str)\n",
    "        entities = [\n",
    "            (\n",
    "                entity[\"entity_name\"],\n",
    "                entity[\"entity_type\"],\n",
    "                entity[\"entity_description\"],\n",
    "            )\n",
    "            for entity in data.get(\"entities\", [])\n",
    "        ]\n",
    "        relationships = [\n",
    "            (\n",
    "                relation[\"source_entity\"],\n",
    "                relation[\"target_entity\"],\n",
    "                relation[\"relation\"],\n",
    "                relation[\"relationship_description\"],\n",
    "            )\n",
    "            for relation in data.get(\"relationships\", [])\n",
    "        ]\n",
    "        return entities, relationships\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error parsing JSON:\", e)\n",
    "        return entities, relationships\n",
    "\n",
    "\n",
    "kg_extractor = GraphRAGExtractor(\n",
    "    llm=llm,\n",
    "    extract_prompt=KG_TRIPLET_EXTRACT_TMPL,\n",
    "    max_paths_per_chunk=2,\n",
    "    parse_fn=parse_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "490dc268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text: 100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.78it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "\n",
    "index = PropertyGraphIndex(\n",
    "    nodes=nodes,\n",
    "    property_graph_store=GraphRAGStore(),\n",
    "    kg_extractors=[kg_extractor],\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e120370d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(EntityNode(label='Person', embedding=None, properties={'entity_description': 'A physicist who introduced the idea of quantized energy levels in 1900 to explain blackbody radiation, contributing to the origins of quantum mechanics.', 'triplet_source_id': '63381b8a-5226-4886-a823-f5d192731524'}, name='Max Planck'),\n",
       "  Relation(label='contributed to', source_id='Max Planck', target_id='Quantum Mechanics', properties={'relationship_description': \"Max Planck's work on quantized energy levels in 1900 was a foundational contribution to the development of quantum mechanics.\", 'triplet_source_id': '63381b8a-5226-4886-a823-f5d192731524'}),\n",
       "  EntityNode(label='Scientific Theory', embedding=None, properties={'entity_description': 'A fundamental theory in physics describing nature at the smallest scales, developed in the early 20th century, revolutionizing our understanding of the physical world. It has profound implications beyond physics, laying the foundation for quantum chemistry, semiconductors, and emerging fields like quantum computing and quantum cryptography.', 'triplet_source_id': '63381b8a-5226-4886-a823-f5d192731524'}, name='Quantum Mechanics')),\n",
       " (EntityNode(label='Person', embedding=None, properties={'entity_description': 'A physicist who explained the photoelectric effect in 1905 by proposing that light consists of discrete packets of energy called photons.  This work earned him the Nobel Prize in Physics in 1921 and further developed the concepts of quantum mechanics.', 'triplet_source_id': '63381b8a-5226-4886-a823-f5d192731524'}, name='Albert Einstein'),\n",
       "  Relation(label='contributed to', source_id='Albert Einstein', target_id='Quantum Mechanics', properties={'relationship_description': \"Albert Einstein's explanation of the photoelectric effect further developed the concepts of quantum mechanics.\", 'triplet_source_id': '63381b8a-5226-4886-a823-f5d192731524'}),\n",
       "  EntityNode(label='Scientific Theory', embedding=None, properties={'entity_description': 'A fundamental theory in physics describing nature at the smallest scales, developed in the early 20th century, revolutionizing our understanding of the physical world. It has profound implications beyond physics, laying the foundation for quantum chemistry, semiconductors, and emerging fields like quantum computing and quantum cryptography.', 'triplet_source_id': '63381b8a-5226-4886-a823-f5d192731524'}, name='Quantum Mechanics'))]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.property_graph_store.graph.get_triplets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fee454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EntityNode(label='Person', embedding=None, properties={'entity_description': 'A physicist who explained the photoelectric effect in 1905 by proposing that light consists of discrete packets of energy called photons.  This work earned him the Nobel Prize in Physics in 1921 and further developed the concepts of quantum mechanics.', 'triplet_source_id': '63381b8a-5226-4886-a823-f5d192731524'}, name='Albert Einstein')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(index.property_graph_store.graph.nodes.values())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da700d8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Relation(label='contributed to', source_id='Max Planck', target_id='Quantum Mechanics', properties={'relationship_description': \"Max Planck's work on quantized energy levels in 1900 was a foundational contribution to the development of quantum mechanics.\", 'triplet_source_id': '63381b8a-5226-4886-a823-f5d192731524'})"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(index.property_graph_store.graph.relations.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "000cf864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Max Planck's work on quantized energy levels in 1900 was a foundational contribution to the development of quantum mechanics.\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(index.property_graph_store.graph.relations.values())[0].properties[\n",
    "    \"relationship_description\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dc94fabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\OneDrive\\Documents\\Repos\\note-to-knowledge\\venv\\Lib\\site-packages\\graspologic\\partition\\leiden.py:607: UserWarning: Leiden partitions do not contain all nodes from the input graph because input graph contained isolate nodes.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_200\\758028960.py:29: DeprecationWarning: Call to deprecated class Gemini. (Should use `llama-index-llms-google-genai` instead, using Google's latest unified SDK. See: https://docs.llamaindex.ai/en/stable/examples/llm/google_genai/)\n",
      "  response = Gemini().chat(messages)\n"
     ]
    }
   ],
   "source": [
    "index.property_graph_store.build_communities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d8647c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = GraphRAGQueryEngine(\n",
    "    graph_store=index.property_graph_store, llm=llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "32cc2ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Planck's quantized energy levels and Einstein's explanation of the photoelectric effect were foundational to the development of quantum mechanics."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What are the main news discussed in the document?\"\n",
    ")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "500e0271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Einstein explained the photoelectric effect, advancing quantum mechanics."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = query_engine.query(\"What waws the contribution of Albert Einstein?\")\n",
    "display(Markdown(f\"{response.response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bb7a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyvis gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e04e2cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entity_description': 'A physicist who introduced the idea of quantized energy levels in 1900 to explain blackbody radiation, contributing to the origins of quantum mechanics.',\n",
       " 'triplet_source_id': '63381b8a-5226-4886-a823-f5d192731524'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets = index.property_graph_store.graph.get_triplets()\n",
    "trip = triplets[0]\n",
    "trip[0].properties\n",
    "    # source = triplets[i][0].properties.get(\"name\") or triplets[i][0].properties.get(\"id\") or \"Unknown\"\n",
    "    # relation = triplets[i][1].label\n",
    "    # target = triplets[i][2].properties.get(\"name\") or triplets[i+2].properties.get(\"id\") or \"Unknown\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "9a5fee62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(EntityNode(label='Person', embedding=None, properties={'entity_description': 'A physicist who introduced the idea of quantized energy levels in 1900 to explain blackbody radiation, contributing to the origins of quantum mechanics.', 'triplet_source_id': '63381b8a-5226-4886-a823-f5d192731524'}, name='Max Planck'), Relation(label='contributed to', source_id='Max Planck', target_id='Quantum Mechanics', properties={'relationship_description': \"Max Planck's work on quantized energy levels in 1900 was a foundational contribution to the development of quantum mechanics.\", 'triplet_source_id': '63381b8a-5226-4886-a823-f5d192731524'}), EntityNode(label='Scientific Theory', embedding=None, properties={'entity_description': 'A fundamental theory in physics describing nature at the smallest scales, developed in the early 20th century, revolutionizing our understanding of the physical world. It has profound implications beyond physics, laying the foundation for quantum chemistry, semiconductors, and emerging fields like quantum computing and quantum cryptography.', 'triplet_source_id': '63381b8a-5226-4886-a823-f5d192731524'}, name='Quantum Mechanics'))\n"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import webbrowser\n",
    "\n",
    "# --- Get triplets from LlamaIndex GraphRAG\n",
    "triplets = index.property_graph_store.graph.get_triplets()\n",
    "\n",
    "# --- Colors for different entity types\n",
    "type_colors = {\n",
    "    \"Person\": \"#FF6961\",              # red\n",
    "    \"Scientific Theory\": \"#779ECB\",   # blue\n",
    "    \"Concept\": \"#77DD77\",             # green\n",
    "    \"Location\": \"#FFD700\",            # yellow\n",
    "    \"Organization\": \"#FFB347\",        # orange\n",
    "    \"Unknown\": \"#D3D3D3\"              # grey fallback\n",
    "}\n",
    "\n",
    "def build_and_open_graph(triplets):\n",
    "    net = Network(height=\"750px\", width=\"100%\", directed=True, notebook=False)\n",
    "    \n",
    "    for i in range(0, len(triplets), 3):\n",
    "        print(triplets[i])\n",
    "        try:\n",
    "            node1 = triplets[i][0]\n",
    "            edge = triplets[i][1]\n",
    "            node2 = triplets[i][2]\n",
    "\n",
    "            # Get node info\n",
    "            source = node1.name\n",
    "            source_type = node1.label\n",
    "            source_desc = node1.properties.get(\"entity_description\", \"\")\n",
    "\n",
    "            target = node2.name or node2.properties.get(\"id\") or \"Unknown\"\n",
    "            target_type = node2.label or \"Unknown\"\n",
    "            target_desc = node2.properties.get(\"entity_description\", \"\")\n",
    "\n",
    "            relation = edge.label or \"related_to\"\n",
    "            relation_desc = edge.properties.get(\"relation_description\", \"\")\n",
    "\n",
    "            # Add source node\n",
    "            net.add_node(\n",
    "                source,\n",
    "                label=source,\n",
    "                title=f\"{source_type}: {source_desc}\",\n",
    "                color=type_colors.get(source_type, type_colors[\"Unknown\"])\n",
    "            )\n",
    "\n",
    "            # Add target node\n",
    "            net.add_node(\n",
    "                target,\n",
    "                label=target,\n",
    "                title=f\"{target_type}: {target_desc}\",\n",
    "                color=type_colors.get(target_type, type_colors[\"Unknown\"])\n",
    "            )\n",
    "\n",
    "            # Add edge with tooltip\n",
    "            net.add_edge(\n",
    "                source,\n",
    "                target,\n",
    "                label=relation,\n",
    "                title=relation_desc\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping triplet group {i}-{i+2}: {e}\")\n",
    "            continue\n",
    "\n",
    "    net.repulsion()\n",
    "    output_path = \"graph.html\"\n",
    "    net.save_graph(output_path)\n",
    "    webbrowser.open(f\"file://{os.path.abspath(output_path)}\")\n",
    "\n",
    "# --- Run it\n",
    "build_and_open_graph(triplets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f7904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "import gradio as gr\n",
    "from llama_index.graph_stores import SimpleGraphStore  # or your actual GraphStore class\n",
    "\n",
    "# --- Assuming you already have the index with property_graph_store\n",
    "triplets = index.property_graph_store.graph.get_triplets()\n",
    "\n",
    "def create_graph_html(triplets):\n",
    "    g = Network(height=\"600px\", width=\"100%\", directed=True)\n",
    "\n",
    "    for i in range(0, len(triplets), 3):\n",
    "        source = triplets[i].properties.get(\"name\") or triplets[i].properties.get(\"id\") or \"Unknown\"\n",
    "        relation = triplets[i+1].label\n",
    "        target = triplets[i+2].properties.get(\"name\") or triplets[i+2].properties.get(\"id\") or \"Unknown\"\n",
    "        \n",
    "        g.add_node(source, label=source)\n",
    "        g.add_node(target, label=target)\n",
    "        g.add_edge(source, target, label=relation)\n",
    "\n",
    "    g.repulsion()  # Makes layout prettier\n",
    "    g_html_path = \"graph.html\"\n",
    "    g.show(g_html_path)\n",
    "    \n",
    "    with open(g_html_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "# --- Gradio Interface\n",
    "def show_graph():\n",
    "    return create_graph_html(triplets)\n",
    "\n",
    "gr.Interface(fn=show_graph, inputs=[], outputs=gr.HTML()).launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
